{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Echocardiogram dataset\n",
    "\n",
    "dataset from: https://archive.ics.uci.edu/ml/datasets/Echocardiogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./echocardiogram.data', header=None)\n",
    "df.columns = ['survival', 'still-alive', 'age-at-heart-attack', 'pericardial-effusion',\n",
    "             'fractional-shortening', 'epss', 'lvdd', 'wall-motion-score', 'wall-motion-index',\n",
    "             'mult', 'name', 'group', 'alive_at_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survival</th>\n",
       "      <th>still-alive</th>\n",
       "      <th>age-at-heart-attack</th>\n",
       "      <th>pericardial-effusion</th>\n",
       "      <th>fractional-shortening</th>\n",
       "      <th>epss</th>\n",
       "      <th>lvdd</th>\n",
       "      <th>wall-motion-score</th>\n",
       "      <th>wall-motion-index</th>\n",
       "      <th>mult</th>\n",
       "      <th>name</th>\n",
       "      <th>group</th>\n",
       "      <th>alive_at_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>0.260</td>\n",
       "      <td>9</td>\n",
       "      <td>4.600</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>name</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0.380</td>\n",
       "      <td>6</td>\n",
       "      <td>4.100</td>\n",
       "      <td>14</td>\n",
       "      <td>1.700</td>\n",
       "      <td>0.588</td>\n",
       "      <td>name</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0.260</td>\n",
       "      <td>4</td>\n",
       "      <td>3.420</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>name</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0.253</td>\n",
       "      <td>12.062</td>\n",
       "      <td>4.603</td>\n",
       "      <td>16</td>\n",
       "      <td>1.450</td>\n",
       "      <td>0.788</td>\n",
       "      <td>name</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0.160</td>\n",
       "      <td>22</td>\n",
       "      <td>5.750</td>\n",
       "      <td>18</td>\n",
       "      <td>2.250</td>\n",
       "      <td>0.571</td>\n",
       "      <td>name</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  survival still-alive age-at-heart-attack pericardial-effusion  \\\n",
       "0       11           0                  71                    0   \n",
       "1       19           0                  72                    0   \n",
       "2       16           0                  55                    0   \n",
       "3       57           0                  60                    0   \n",
       "4       19           1                  57                    0   \n",
       "\n",
       "  fractional-shortening    epss   lvdd wall-motion-score wall-motion-index  \\\n",
       "0                 0.260       9  4.600                14                 1   \n",
       "1                 0.380       6  4.100                14             1.700   \n",
       "2                 0.260       4  3.420                14                 1   \n",
       "3                 0.253  12.062  4.603                16             1.450   \n",
       "4                 0.160      22  5.750                18             2.250   \n",
       "\n",
       "    mult  name group alive_at_1  \n",
       "0      1  name     1          0  \n",
       "1  0.588  name     1          0  \n",
       "2      1  name     1          0  \n",
       "3  0.788  name     1          0  \n",
       "4  0.571  name     1          0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132, 13)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survival                 0\n",
       "still-alive              0\n",
       "age-at-heart-attack      0\n",
       "pericardial-effusion     0\n",
       "fractional-shortening    0\n",
       "epss                     0\n",
       "lvdd                     0\n",
       "wall-motion-score        0\n",
       "wall-motion-index        0\n",
       "mult                     0\n",
       "name                     0\n",
       "group                    0\n",
       "alive_at_1               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop redundant column,\n",
    "# according to data description group,\n",
    "# mult -- a derivate var which can be ignored\n",
    "# group -- meaningless, ignore it\n",
    "df = df.drop(['group', 'name', 'mult'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 132 entries, 0 to 131\n",
      "Data columns (total 10 columns):\n",
      "survival                 132 non-null object\n",
      "still-alive              132 non-null object\n",
      "age-at-heart-attack      132 non-null object\n",
      "pericardial-effusion     132 non-null object\n",
      "fractional-shortening    132 non-null object\n",
      "epss                     132 non-null object\n",
      "lvdd                     132 non-null object\n",
      "wall-motion-score        132 non-null object\n",
      "wall-motion-index        132 non-null object\n",
      "alive_at_1               132 non-null object\n",
      "dtypes: object(10)\n",
      "memory usage: 10.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# Let's inspect the datatype of our feature\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the data description, all features suppose to be numerical except names, thus we need to examine the missing attribute values: (denoted by \"?\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the no. of missing values from every features\n",
    "def missing_value(df, val):\n",
    "    for i in df.columns:\n",
    "        if (df[i].values == val).any():\n",
    "            print(i,':', df[i].value_counts()[val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survival : 2\n",
      "still-alive : 1\n",
      "age-at-heart-attack : 5\n",
      "pericardial-effusion : 1\n",
      "fractional-shortening : 8\n",
      "epss : 15\n",
      "lvdd : 11\n",
      "wall-motion-score : 4\n",
      "wall-motion-index : 1\n",
      "alive_at_1 : 58\n"
     ]
    }
   ],
   "source": [
    "missing_value(df, '?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting missing value from features step by step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we do not know the no. of months the patient survived, we can just drop the rows\n",
    "# (avoid guessing or using the mode since other predictor variables do have an effect on the survival)\n",
    "df = df.drop(df[df['survival'] == '?'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age-at-heart-attack : 5\n",
      "fractional-shortening : 7\n",
      "epss : 14\n",
      "lvdd : 10\n",
      "wall-motion-score : 3\n",
      "wall-motion-index : 1\n",
      "alive_at_1 : 57\n"
     ]
    }
   ],
   "source": [
    "# Printing the no. of missing values from every features after removed missing value from survival\n",
    "missing_value(df, '?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fractional-shortening : 6\n",
      "epss : 14\n",
      "lvdd : 9\n",
      "wall-motion-score : 3\n",
      "wall-motion-index : 1\n",
      "alive_at_1 : 53\n"
     ]
    }
   ],
   "source": [
    "# still-alive has been removed as well along with survival, looks like these 2 variable are correlated (EDA later)\n",
    "\n",
    "# Dropping age-at-heart-attack since these are numerical value we couldn't infer much from their statistics \n",
    "df = df.drop(df[df['age-at-heart-attack'] == '?'].index)\n",
    "\n",
    "# rerun the no. of missing values from every features after removed missing value from age-at-heart-attack\n",
    "missing_value(df, '?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epss : 10\n",
      "lvdd : 4\n",
      "wall-motion-score : 2\n",
      "wall-motion-index : 1\n",
      "alive_at_1 : 51\n"
     ]
    }
   ],
   "source": [
    "# pericardial-effusion has been removed along with age-at-heart-attack, possibly correlated (EDA later)\n",
    "\n",
    "# Let's drop the missing value from the feature fractional-shortening\n",
    "df = df.drop(df[df['fractional-shortening'] == '?'].index)\n",
    "\n",
    "# rerun the no. of missing values from every features after removed missing value from fractional-shortening\n",
    "missing_value(df, '?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lvdd : 1\n",
      "wall-motion-score : 2\n",
      "wall-motion-index : 1\n",
      "alive_at_1 : 46\n"
     ]
    }
   ],
   "source": [
    "# 4 and 5 rows from epss and lvdd has been removed respectively along with fractional-shortening as well, possibly correlated (EDA later)\n",
    "\n",
    "# Let's drop the value '?' from the feature epss\n",
    "df = df.drop(df[df['epss'] == '?'].index)\n",
    "\n",
    "# rerun the no. of missing values from every features after removed missing value from epss\n",
    "missing_value(df, '?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wall-motion-score : 2\n",
      "wall-motion-index : 1\n",
      "alive_at_1 : 46\n"
     ]
    }
   ],
   "source": [
    "# 3 samples has been removed from lvdd along with epss, possibly correlated (EDA later)\n",
    "\n",
    "# Let's drop the value '?' from the feature lvdd\n",
    "df = df.drop(df[df['lvdd'] == '?'].index)\n",
    "\n",
    "# rerun the no. of missing values from every features after removed missing value from lvdd\n",
    "missing_value(df, '?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alive_at_1 : 45\n"
     ]
    }
   ],
   "source": [
    "# According to data description we shall use just wall-motion-index instead of wall-motion-score so,\n",
    "# Possibly to examine the relationship between wall-motion-score and wall-motion-index\n",
    "df = df.drop(df[df['wall-motion-score'] == '?'].index)\n",
    "\n",
    "# rerun the no. of missing values from every features after removed missing value from wall-motion-score\n",
    "missing_value(df, '?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is still 45 missing values from the response; hence we should exclude these missing samples for prediction later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are all the samples with missing response\n",
    "missing_response = df_new[df_new['alive_at_1'] == '?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.groupby(['survival', 'still-alive'])[['alive_at_1']].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all the samples with missing response\n",
    "df_new = df_new.drop(df_new[df_new['alive_at_1'] == '?'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((61, 10), (45, 10))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.shape, missing_response.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df_new.iloc[:, :-1]\n",
    "y = df_new['alive_at_1']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Confusion Matrix\n",
      "\n",
      "Predicted   0   1\n",
      "Actual           \n",
      "0          31   0\n",
      "1           0  11\n",
      "\n",
      "Train accuracy score: 1.0\n",
      "\n",
      "Test Confusion Matrix\n",
      "\n",
      "Predicted   0  1\n",
      "Actual          \n",
      "0          13  0\n",
      "1           0  6\n",
      "\n",
      "Test accuracy score: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "print('\\nTrain Confusion Matrix\\n\\n', pd.crosstab(y_train, lr.predict(X_train),\n",
    "           rownames=['Actual'], colnames=['Predicted']), sep='')\n",
    "print('\\nTrain accuracy score:', round(accuracy_score(y_train, lr.predict(X_train))))\n",
    "\n",
    "print('\\nTest Confusion Matrix\\n\\n', pd.crosstab(y_test, lr.predict(X_test),\n",
    "           rownames=['Actual'], colnames=['Predicted']), sep='')\n",
    "print('\\nTest accuracy score:', round(accuracy_score(y_test, lr.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we got perfect accuracy on train and test using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Confusion Matrix\n",
      "\n",
      "Predicted   0   1\n",
      "Actual           \n",
      "0          31   0\n",
      "1           0  11\n",
      "\n",
      "Train accuracy score: 1.0\n",
      "\n",
      "Test Confusion Matrix\n",
      "\n",
      "Predicted   0  1\n",
      "Actual          \n",
      "0          13  0\n",
      "1           0  6\n",
      "\n",
      "Test accuracy score: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "print('\\nTrain Confusion Matrix\\n\\n', pd.crosstab(y_train, rf.predict(X_train),\n",
    "           rownames=['Actual'], colnames=['Predicted']), sep='')\n",
    "print('\\nTrain accuracy score:', round(accuracy_score(y_train, rf.predict(X_train))))\n",
    "\n",
    "print('\\nTest Confusion Matrix\\n\\n', pd.crosstab(y_test, rf.predict(X_test),\n",
    "           rownames=['Actual'], colnames=['Predicted']), sep='')\n",
    "print('\\nTest accuracy score:', round(accuracy_score(y_test, rf.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest yielded perfect score as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.groupby(['survival', 'still-alive'])[['alive_at_1']].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are our predicted data on the missing response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's predict on our missing_response data\n",
    "prediction = lr.predict(missing_response.iloc[:, :-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
